{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xml.etree.cElementTree as ET\n",
    "import xml\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/Users/apple/Documents/Git/OderFit-Zalo_AI_Hacka/'\n",
    "image_path = '/Users/apple/Documents/Git/OderFit-Zalo_AI_Hacka/zai2019_hackaton_train/images/train/'\n",
    "annotation_path = '/Users/apple/Documents/Git/OderFit-Zalo_AI_Hacka/zai2019_hackaton_train/annotations/ninedash_keypoints_train.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(annotation_path) as json_file:\n",
    "    data = json.load(json_file)\n",
    "    annotations = data['annotations']\n",
    "    annotations = np.array(annotations)\n",
    "    images = data['images']\n",
    "    images = np.array(images)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_anno(img_id):\n",
    "    anno = []\n",
    "    for ann in annotations:\n",
    "        if img_id == ann['image_id']:\n",
    "            anno.append(ann)\n",
    "        \n",
    "    return anno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([{'file_name': '000.jpg', 'height': 796, 'id': 0, 'license': 1, 'width': 1000},\n",
       "       {'file_name': '001.jpg', 'height': 350, 'id': 1, 'license': 1, 'width': 466},\n",
       "       {'file_name': '002.jpg', 'height': 473, 'id': 2, 'license': 1, 'width': 622},\n",
       "       ...,\n",
       "       {'file_name': '2597.jpg', 'height': 720, 'id': 2597, 'license': 1, 'width': 1280},\n",
       "       {'file_name': '2598.jpg', 'height': 755, 'id': 2598, 'license': 1, 'width': 700},\n",
       "       {'file_name': '2599.jpg', 'height': 745, 'id': 2599, 'license': 1, 'width': 2048}],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_infor():\n",
    "    count = 0\n",
    "    data_train = []\n",
    "    \n",
    "    for img in images:\n",
    "#         count += 1\n",
    "        file_name = img['file_name']\n",
    "        img_id = img['id']\n",
    "        width = img['width']\n",
    "        height = img['height']\n",
    "#         img_array = np.array(cv2.imread(image_path+file_name))        \n",
    "        annos = get_anno(img_id)\n",
    "        bboxes = []\n",
    "        \n",
    "        for anno in annos:\n",
    "            bbox = anno['bbox']\n",
    "            (x, y, w, h) = bbox\n",
    "            bboxes.append(bbox)\n",
    "            \n",
    "        data_train.append({'img_path': image_path+file_name, 'bboxes': bboxes, 'height': height, 'width': width})\n",
    "        \n",
    "    return data_train\n",
    "        \n",
    "#             cv2.rectangle(img_array, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "#             plt.imshow(img_array)\n",
    "        \n",
    "#         if count == 4:\n",
    "#             break\n",
    "#     return anno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bboxes': [[388, 130, 447, 599]],\n",
      " 'height': 796,\n",
      " 'img_path': '/Users/apple/Documents/Git/OderFit-Zalo_AI_Hacka/zai2019_hackaton_train/images/train/000.jpg',\n",
      " 'width': 1000}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "data_train = get_img_infor()  \n",
    "pprint(data_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_img_infor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "XML_TRAIN_FD = \"/Users/apple/Documents/Git/OderFit-Zalo_AI_Hacka/xmls/\"\n",
    "TRAIN_FD = image_path\n",
    "\n",
    "def gen_xml_files(img_fp, labels, save_xml_fd=XML_TRAIN_FD):\n",
    "    img_fn = img_fp.split(\"/\")[-1].split(\".\")[0]\n",
    "    img = cv2.imread(img_fp)[:, :, ::-1]\n",
    "\n",
    "#     try:\n",
    "#         labels = np.array(labels.split(' ')).reshape(-1, 5)\n",
    "#     except AttributeError:\n",
    "#         return None\n",
    "\n",
    "    root = ET.Element(\"annotation\")\n",
    "    ET.SubElement(root, \"folder\").text = TRAIN_FD\n",
    "    ET.SubElement(root, \"filename\").text = img_fn + \".jpg\"\n",
    "    ET.SubElement(root, \"path\").text = os.path.join(TRAIN_FD, img_fn) + \".jpg\"\n",
    "\n",
    "    source = ET.SubElement(root, \"source\")\n",
    "    ET.SubElement(source, \"database\").text = \"Unknown\"\n",
    "\n",
    "    size = ET.SubElement(root, \"size\")\n",
    "    height, width, depth = img.shape\n",
    "    ET.SubElement(size, \"width\").text = str(width)\n",
    "    ET.SubElement(size, \"height\").text = str(height)\n",
    "    ET.SubElement(size, \"depth\").text = str(depth)\n",
    "\n",
    "    ET.SubElement(root, \"segmented\").text = \"0\"\n",
    "\n",
    "    for x, y, w, h in labels:\n",
    "        xmin, ymin, w, h = int(x), int(y), int(w), int(h)\n",
    "        xmax = xmin + w\n",
    "        ymax = ymin + h\n",
    "\n",
    "        obj = ET.SubElement(root, \"object\")\n",
    "        ET.SubElement(obj, \"name\").text = \"Nine Dash Line\"\n",
    "        ET.SubElement(obj, \"pose\").text = 'Unspecified'\n",
    "        ET.SubElement(obj, \"truncated\").text = '0'\n",
    "        ET.SubElement(obj, \"difficult\").text = '0'\n",
    "\n",
    "        bbox = ET.SubElement(obj, \"bndbox\")\n",
    "        ET.SubElement(bbox, \"xmin\").text = str(xmin)\n",
    "        ET.SubElement(bbox, \"ymin\").text = str(ymin)\n",
    "        ET.SubElement(bbox, \"xmax\").text = str(xmax)\n",
    "        ET.SubElement(bbox, \"ymax\").text = str(ymax)\n",
    "\n",
    "    xml_str = ET.tostring(root).decode(\"utf-8\")\n",
    "    xml_indent = xml.dom.minidom.parseString(xml_str).toprettyxml(indent=\"\\t\")\n",
    "    new_fn = \"{}.xml\".format(img_fn+'.jpg')\n",
    "    new_fn = os.path.join(save_xml_fd, new_fn)\n",
    "    with open(new_fn, \"w\") as f:\n",
    "        f.write(xml_indent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dt in data_train:\n",
    "# #     print('{}---{}'.format(dt['img_path'], dt['bboxes']))\n",
    "#     gen_xml_files(dt['img_path'], dt['bboxes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreprocess:\n",
    "    def __init__(self, width, height, inter=cv2.INTER_AREA):\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.inter = inter\n",
    "        \n",
    "    def preprocess(self, image, bboxes):\n",
    "        (h, w) = image.shape[:2]\n",
    "        bboxes = np.array(bboxes)\n",
    "#         bboxes = [np.array(bbox) for bbox in bboxes]\n",
    "        \n",
    "        if w > h:\n",
    "            ratio = float(w/self.width)\n",
    "            image = imutils.resize(image, width=self.width)\n",
    "        else:\n",
    "            ratio = float(h/self.height)\n",
    "            image = imutils.resize(image, height=self.height)\n",
    "        \n",
    "        padw = int((self.width - image.shape[1]) / 2.0)\n",
    "        padh = int((self.height - image.shape[0]) / 2.0)\n",
    "#         print(bboxes)\n",
    "        bboxes = bboxes / ratio\n",
    "#         print(bboxes, padw, padh)\n",
    "        \n",
    "        if padh > 0:\n",
    "            bboxes = [[bbox[0], bbox[1] + padh, bbox[2], bbox[3] + padh] for bbox in bboxes]\n",
    "        else:\n",
    "            bboxes = [[bbox[0] + padw, bbox[1], bbox[2] + padw, bbox[3]] for bbox in bboxes]\n",
    "        \n",
    "#         print(bboxes)\n",
    "        \n",
    "        image = cv2.copyMakeBorder(image, padh, padh, padw, padw, cv2.BORDER_REPLICATE)\n",
    "        image = cv2.resize(image, (self.width, self.height))\n",
    "            \n",
    "        return image, ratio, bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_fol = '/Users/apple/Documents/Git/OderFit-Zalo_AI_Hacka/zai2019_hackaton_train/images2/'\n",
    "\n",
    "if not os.path.exists(new_train_fol):\n",
    "    os.mkdir(new_train_fol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "constant_width = 640\n",
    "constant_height = 640\n",
    "dt_preprocess = DataPreprocess(constant_height, constant_width)\n",
    "new_data_train = []\n",
    "\n",
    "for dt in data_train:\n",
    "    image_path = dt['img_path']\n",
    "    img_fn = image_path.split(\"/\")[-1].split(\".\")[0]\n",
    "    bboxes = dt['bboxes']\n",
    "    \n",
    "    image = cv2.imread(image_path)\n",
    "    image, ratio, bboxes = dt_preprocess.preprocess(image, bboxes)\n",
    "#     print(bboxes)\n",
    "#     bboxes = [int(bbox * ratio) for bbox in bboxes]\n",
    "    new_img_path = new_train_fol + img_fn + '.jpg'\n",
    "    cv2.imwrite(new_img_path, image)\n",
    "    \n",
    "    new_data_train.append({'img_path': new_img_path, 'bboxes': bboxes, 'width': constant_width, 'height': constant_height})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = new_data_train[0]\n",
    "# test\n",
    "# img_test = cv2.imread(test['img_path']) \n",
    "\n",
    "# cv2.rectangle(img_test, (248, 83+65), (248 + 286, 83 + 383 + 65), (0, 255, 0), 2)\n",
    "# plt.imshow(img_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "for new_dt in new_data_train:\n",
    "#   print('{}---{}'.format(dt['img_path'], dt['bboxes']))\n",
    "    gen_xml_files(new_dt['img_path'], new_dt['bboxes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
